# Sign Language Object Detection using Mediapipe

Welcome to our Sign Language Object Detection project! This collaborative effort is brought to you by Eya Ridene, Mariem Ksontini, and Sandra Mourali.

## Overview

This notebook demonstrates real-time hand gesture recognition for Sign Language using the powerful Mediapipe library. As part of our Personal Professional Project assignment at INSAT, we are excited to share our exploration of applying computer vision techniques to enhance accessibility for the Sign Language community.

## Project Details

- **Major:** Software Engineering
- **University Year:** 2022/2023

## Objective

Our goal is to leverage the capabilities of Mediapipe to accurately detect and interpret hand gestures, thereby facilitating communication for individuals who rely on Sign Language. Through this project, we aim to contribute to the development of accessible and inclusive technologies.

## How to Use

1. Clone the repository to your local machine:

   ```bash
   git clone https://github.com/your-username/sign-language-object-detection.git

   ```

2. Navigate to the project directory:

   ```bash
   cd sign-language-object-detection

   ```

3. Open the notebook using Jupyter or any preferred environment:

   ```bash
   jupyter notebook Sign_Language_Object_Detection.ipynb

   ```

4. Follow the instructions within the notebook to experience real-time Sign Language gesture recognition.

## Dependencies

Ensure that you have the required dependencies installed. You can install them using:
```bash
pip install -r requirements.txt

## Contribution

Feel free to contribute, provide feedback, or report issues. We welcome collaboration and look forward to making this project even more impactful with the help of the open-source community.

Happy coding!
